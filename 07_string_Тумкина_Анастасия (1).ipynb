{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XX-0UZRJJfq1"
      },
      "source": [
        "# Введение в обработку текста на естественном языке"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt9suc81Jfq4"
      },
      "source": [
        "Материалы:\n",
        "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
        "* https://realpython.com/nltk-nlp-python/\n",
        "* https://scikit-learn.org/stable/modules/feature_extraction.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import random"
      ],
      "metadata": {
        "id": "ls0Pvs5HZNre"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('all')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4dBRAp0ruZp",
        "outputId": "f75799d1-5a4a-436c-8bc3-cc6ba8276260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVaED2aZJfq4"
      },
      "source": [
        "## Задачи для совместного разбора"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Puk0zd8fs-A1",
        "outputId": "34762092-16d9-4142-c404-77bd8509eb08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 KB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting docopt>=0.6\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13721 sha256=5c18a904afe5130e948b78532c6829600d54d29015ea6e8444dd8a62ff3498da\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/4a/46/1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
            "Successfully built docopt\n",
            "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HIYUB_FJfq4"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pymorphy2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0w8r2ILJfq5"
      },
      "source": [
        "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3_MeDeKJfq6"
      },
      "outputs": [],
      "source": [
        "text = '''с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.metrics.distance import edit_distance\n",
        "f = open('/content/litw-win.txt', encoding = 'cp1251')\n",
        "words = [i.split()[1] for i in f.readlines()]\n",
        "\n",
        "def f1(word, k):\n",
        "  min_w = {}\n",
        "  for i in words:\n",
        "    min_w[i] = edit_distance(i, word)\n",
        "  msort = sorted(min_w.items(), key=lambda x: x[1])\n",
        "  for i in dict(msort[:k]).keys():\n",
        "    return i\n",
        "\n",
        "rez = ''\n",
        "for i in text.split():\n",
        "  if i in words:\n",
        "    rez += i + ' '\n",
        "  else:\n",
        "    rez += f1(i, 1) + ' '\n",
        "rez"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RI-0qekeuUoF",
        "outputId": "1203bf23-332b-4b63-aa77-49b95c24cfb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'с величайшим усилием выбравшись из потока убегающих людей кутузов со свитой уменьшившейся вдвое поехал на звуки выстрелов русских орудий '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j5pF6reJfq6"
      },
      "source": [
        "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "snb_stemmer_rus = SnowballStemmer('russian')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stopwords_rus = stopwords.words('russian')"
      ],
      "metadata": {
        "id": "H-0ucP324Euo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_z1 = 'Считайте слова из файла litw-win.txt и запишите их в список words. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка words. Считайте, что в слове есть опечатка, если данное слово не содержится в списке words.'\n",
        "for j in nltk.tokenize.word_tokenize(text_z1):\n",
        "  if j.isalpha():\n",
        "    print(j, snb_stemmer_rus.stem(j), lemmatizer.lemmatize(j))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0EkkYpi2zPt",
        "outputId": "600f1802-27c2-474b-aede-d68584235b9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Считайте счита Считайте\n",
            "слова слов слова\n",
            "из из из\n",
            "файла файл файла\n",
            "и и и\n",
            "запишите запиш запишите\n",
            "их их их\n",
            "в в в\n",
            "список список список\n",
            "words words word\n",
            "В в В\n",
            "заданном зада заданном\n",
            "предложении предложен предложении\n",
            "исправьте исправьт исправьте\n",
            "все все все\n",
            "опечатки опечатк опечатки\n",
            "заменив замен заменив\n",
            "слова слов слова\n",
            "с с с\n",
            "опечатками опечатк опечатками\n",
            "на на на\n",
            "ближайшие ближайш ближайшие\n",
            "в в в\n",
            "смысле смысл смысле\n",
            "расстояния расстоян расстояния\n",
            "Левенштейна левенштейн Левенштейна\n",
            "к к к\n",
            "ним ним ним\n",
            "слова слов слова\n",
            "из из из\n",
            "списка списк списка\n",
            "words words word\n",
            "Считайте счита Считайте\n",
            "что что что\n",
            "в в в\n",
            "слове слов слове\n",
            "есть ест есть\n",
            "опечатка опечатк опечатка\n",
            "если есл если\n",
            "данное дан данное\n",
            "слово слов слово\n",
            "не не не\n",
            "содержится содерж содержится\n",
            "в в в\n",
            "списке списк списке\n",
            "words words word\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfRWI6vfJfq6"
      },
      "source": [
        "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи `CountVectorizer`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import (CountVectorizer, TfidfVectorizer)\n",
        "corpus = ['Считайте слова из файла litw-win.txt и запишите их в список words. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка words. Считайте, что в слове есть опечатка, если данное слово не содержится в списке words.']\n",
        "tv = TfidfVectorizer()\n",
        "corpus_tv = tv.fit_transform(corpus)\n",
        "corpus_tv.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGS56vMR6lnp",
        "outputId": "609000fd-16e5-4b5f-e5c3-67a428803f2e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.13245324, 0.13245324, 0.13245324, 0.39735971, 0.13245324,\n",
              "        0.13245324, 0.13245324, 0.13245324, 0.13245324, 0.13245324,\n",
              "        0.13245324, 0.13245324, 0.26490647, 0.13245324, 0.13245324,\n",
              "        0.13245324, 0.13245324, 0.13245324, 0.13245324, 0.13245324,\n",
              "        0.13245324, 0.13245324, 0.13245324, 0.13245324, 0.39735971,\n",
              "        0.13245324, 0.13245324, 0.13245324, 0.13245324, 0.13245324,\n",
              "        0.13245324, 0.13245324, 0.26490647, 0.13245324, 0.13245324]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvbT6-5pJfq6"
      },
      "source": [
        "## Лабораторная работа 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTuXvDFFJfq7"
      },
      "source": [
        "### Расстояние редактирования"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLsGIceRJfq7"
      },
      "source": [
        "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recipes = pd.read_csv('/content/preprocessed_descriptions.csv', delimiter=',')\n",
        "recipes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "WczWvZIiqc5a",
        "outputId": "8ded30b4-647e-466b-b009-35eddc5c80b3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               name  \\\n",
              "0             george s at the cove  black bean soup   \n",
              "1                healthy for them  yogurt popsicles   \n",
              "2                      i can t believe it s spinach   \n",
              "3                              italian  gut busters   \n",
              "4          love is in the air  beef fondue   sauces   \n",
              "...                                             ...   \n",
              "29995  zurie s holey rustic olive and cheddar bread   \n",
              "29996          zwetschgenkuchen  bavarian plum cake   \n",
              "29997   zwiebelkuchen   southwest german onion cake   \n",
              "29998                                   zydeco soup   \n",
              "29999        cookies by design   cookies on a stick   \n",
              "\n",
              "                               preprocessed_descriptions  \n",
              "0      an original recipe created by chef scott meska...  \n",
              "1      my children and their friends ask for my homem...  \n",
              "2                  these were so go it surprised even me  \n",
              "3      my sisterinlaw made these for us at a family g...  \n",
              "4      i think a fondue is a very romantic casual din...  \n",
              "...                                                  ...  \n",
              "29995  this is based on a french recipe but i changed...  \n",
              "29996  this is a traditional fresh plum cake thought ...  \n",
              "29997  this is a traditional late summer early fall s...  \n",
              "29998  this is a delicious soup that i originally fou...  \n",
              "29999  ive heard of the cookies by design company but...  \n",
              "\n",
              "[30000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e87e3c05-85f2-403d-a371-8d0ce5cd564d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>preprocessed_descriptions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>george s at the cove  black bean soup</td>\n",
              "      <td>an original recipe created by chef scott meska...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>healthy for them  yogurt popsicles</td>\n",
              "      <td>my children and their friends ask for my homem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i can t believe it s spinach</td>\n",
              "      <td>these were so go it surprised even me</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>italian  gut busters</td>\n",
              "      <td>my sisterinlaw made these for us at a family g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>love is in the air  beef fondue   sauces</td>\n",
              "      <td>i think a fondue is a very romantic casual din...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>zurie s holey rustic olive and cheddar bread</td>\n",
              "      <td>this is based on a french recipe but i changed...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>zwetschgenkuchen  bavarian plum cake</td>\n",
              "      <td>this is a traditional fresh plum cake thought ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>zwiebelkuchen   southwest german onion cake</td>\n",
              "      <td>this is a traditional late summer early fall s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>zydeco soup</td>\n",
              "      <td>this is a delicious soup that i originally fou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>cookies by design   cookies on a stick</td>\n",
              "      <td>ive heard of the cookies by design company but...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e87e3c05-85f2-403d-a371-8d0ce5cd564d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e87e3c05-85f2-403d-a371-8d0ce5cd564d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e87e3c05-85f2-403d-a371-8d0ce5cd564d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = set()\n",
        "for i in recipes.preprocessed_descriptions:\n",
        "  for j in nltk.word_tokenize(str(i)):\n",
        "      words.add(j)\n",
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-Smsm6YsNrN",
        "outputId": "0d74a4f2-3553-476c-9bd2-12b6d7f22d4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mesclun',\n",
              " 'lynched',\n",
              " '00mg',\n",
              " 'snapper',\n",
              " 'daykind',\n",
              " 'talk',\n",
              " 'queensland',\n",
              " 'secord',\n",
              " '104301',\n",
              " 'brussels',\n",
              " 'chappati',\n",
              " 'violet',\n",
              " 'payday',\n",
              " 'sailing',\n",
              " 'bali',\n",
              " 'animal',\n",
              " 'golubtsy',\n",
              " 'sweaty',\n",
              " 'accordingly',\n",
              " 'carroll',\n",
              " 'christmascookiescom',\n",
              " 'tastessubmitted',\n",
              " 'supplies',\n",
              " 'unsweetened',\n",
              " 'cases',\n",
              " 'glamorous',\n",
              " 'tandori',\n",
              " 'accidently',\n",
              " 'calville',\n",
              " 'marascas',\n",
              " 'shreddingmincing',\n",
              " 'nutmeginfused',\n",
              " 'improved',\n",
              " 'yummyzwt3',\n",
              " 'saidlittle',\n",
              " 'luau',\n",
              " 'visible',\n",
              " 'safekeeping',\n",
              " 'warman',\n",
              " 'rather',\n",
              " 'cookieshttpwwwelanaspantrycomlemonlavendercookies',\n",
              " '55905',\n",
              " 'mopping',\n",
              " 'kuzbara',\n",
              " 'leavening',\n",
              " 'chocolatedont',\n",
              " 'brined',\n",
              " 'lay',\n",
              " 'lessoneverything',\n",
              " 'liquidit',\n",
              " 'bakeprep',\n",
              " 'game',\n",
              " 'jeni',\n",
              " 'hardtofind',\n",
              " '700',\n",
              " 'involved',\n",
              " '8the',\n",
              " 'syndicated',\n",
              " 'offshoot',\n",
              " 'enjoying',\n",
              " 'himonly',\n",
              " 'tradionally',\n",
              " 'combinationuntil',\n",
              " 'caerphilly',\n",
              " 'ita',\n",
              " 'iteven',\n",
              " 'eve',\n",
              " 'posterity',\n",
              " 'slowcooking',\n",
              " 'wellkeeps',\n",
              " 'torgo',\n",
              " 'workmates',\n",
              " 'submitter',\n",
              " 'buttertalk',\n",
              " 'vahterzoy',\n",
              " 'hunks',\n",
              " 'flannel',\n",
              " 'chilidifficulty',\n",
              " 'disposible',\n",
              " 'confectionery',\n",
              " 'prematurely',\n",
              " 'chimis',\n",
              " 'sylvias',\n",
              " 'sbarros',\n",
              " 'twenty',\n",
              " 'karnataka',\n",
              " '444676',\n",
              " 'roadit',\n",
              " 'bourguignon',\n",
              " 'flatbed',\n",
              " 'chioces',\n",
              " 'httpdavesgardencomcookbookviewentryphprid1637',\n",
              " 'allbutter',\n",
              " 'ree',\n",
              " 'wrinkled',\n",
              " 'comment',\n",
              " 'between',\n",
              " 'ciders',\n",
              " 'coldpack',\n",
              " 'flexibility',\n",
              " 'quit',\n",
              " 'cinnamoney',\n",
              " 'candycook',\n",
              " 'remarkably',\n",
              " 'foodpickiest',\n",
              " 'traysthis',\n",
              " 'cheeseits',\n",
              " 'secondclass',\n",
              " 'hostesscook',\n",
              " 'luchows',\n",
              " 'affects',\n",
              " 'fairhope',\n",
              " '182',\n",
              " 'enamel',\n",
              " 'tappas',\n",
              " 'flush',\n",
              " 'liqueurs',\n",
              " 'flavorshot',\n",
              " 'capsicums',\n",
              " 'committ',\n",
              " 'smokiness',\n",
              " 'encyclopedic',\n",
              " 'samosa',\n",
              " 'kpauls',\n",
              " 'httprecipeshowstuffworkscomvalastroshrimpscampirecipehtm',\n",
              " 'sturgis',\n",
              " 'helping',\n",
              " '1300',\n",
              " 'staying',\n",
              " 'definition',\n",
              " 'center',\n",
              " 'monty',\n",
              " 'everythingenjoy',\n",
              " 'boilingjust',\n",
              " '210',\n",
              " '525',\n",
              " 'karlsen',\n",
              " 'applescherriescom',\n",
              " 'lauberge',\n",
              " 'neighborsand',\n",
              " 'pastic',\n",
              " 'concur',\n",
              " 'contest',\n",
              " 'paprikas',\n",
              " 'dayglo',\n",
              " '27361',\n",
              " '206230your',\n",
              " 'topper',\n",
              " 'repeating',\n",
              " 'noon',\n",
              " 'sandler',\n",
              " 'faint',\n",
              " 'zwt6i',\n",
              " 'loti',\n",
              " 'toula',\n",
              " 'naturally',\n",
              " 'ingest',\n",
              " 'beads',\n",
              " 'dunbars',\n",
              " 'cornbleets',\n",
              " 'whilenote',\n",
              " 'clubs',\n",
              " 'wildflower',\n",
              " 'advanced',\n",
              " 'ummibrahim',\n",
              " 'breadbaguette',\n",
              " 'marrow',\n",
              " 'peppermint',\n",
              " 'bursting',\n",
              " 'hater',\n",
              " 'personalized',\n",
              " 'hami',\n",
              " 'chilispiced',\n",
              " 'fresheri',\n",
              " 'frostingicing',\n",
              " 'peel',\n",
              " 'mealnot',\n",
              " '25gfiber',\n",
              " 'stl',\n",
              " 'locker',\n",
              " 'dorset',\n",
              " 'favouritesthe',\n",
              " 'grownups',\n",
              " 'estimation',\n",
              " 'breyers',\n",
              " 'lettucepea',\n",
              " 'brazilnuts',\n",
              " 'laird',\n",
              " 'workable',\n",
              " 'antioxidantladen',\n",
              " 'clifford',\n",
              " 'parma',\n",
              " 'rollsmy',\n",
              " 'adddition',\n",
              " 'flakey',\n",
              " 'committed',\n",
              " 'crumble',\n",
              " 'wwii',\n",
              " 'kween',\n",
              " 'bhgcom',\n",
              " 'kiangsnaije',\n",
              " 'stepsister',\n",
              " 'hominy',\n",
              " 'slipping',\n",
              " 'skills',\n",
              " 'flakesdelicious',\n",
              " 'fredricksburg',\n",
              " 'realy',\n",
              " 'sought',\n",
              " 'islandteashopcom',\n",
              " 'aand',\n",
              " 'delicatessen',\n",
              " 'compromise',\n",
              " 'herbamare',\n",
              " 'pounds',\n",
              " 'homecomings',\n",
              " 'sooni',\n",
              " 'salon',\n",
              " 'loudly',\n",
              " 'yee',\n",
              " 'aoli',\n",
              " 'overheated',\n",
              " 'weave',\n",
              " 'recipe427545',\n",
              " 'treliving',\n",
              " 'wheatglutenfree',\n",
              " 'surf',\n",
              " 'easycrusty',\n",
              " 'republican',\n",
              " 'ripening',\n",
              " 'blend',\n",
              " 'allergy',\n",
              " 'subway',\n",
              " 'symbolizes',\n",
              " 'usally',\n",
              " 'nickey',\n",
              " 'dils',\n",
              " 'meatloaves',\n",
              " 'salting',\n",
              " 'customising',\n",
              " 'jack',\n",
              " 'exterior',\n",
              " 'lieb',\n",
              " 'wwwsouthbeachdietplancom',\n",
              " 'pantryit',\n",
              " '1969',\n",
              " 'happiness',\n",
              " 'donkeys',\n",
              " 'nonpinto',\n",
              " 'wwwmccormickcom',\n",
              " 'goodcan',\n",
              " 'pizzelles',\n",
              " 'miniature',\n",
              " 'httpwwwbolojicomrecipes05htmthe',\n",
              " 'crumbs',\n",
              " 'treated',\n",
              " 'sortun',\n",
              " 'standin',\n",
              " 'coffeecake',\n",
              " 'kabsah',\n",
              " 'robot',\n",
              " 'subtleties',\n",
              " 'pella',\n",
              " 'papapotato',\n",
              " 'cuban',\n",
              " 'quarter',\n",
              " 'several',\n",
              " 'stewsoup',\n",
              " 'favoritesnote',\n",
              " 'amend',\n",
              " 'frangelico',\n",
              " 'soggyby',\n",
              " 'ruokaviini',\n",
              " 'splatter',\n",
              " 'burkhard',\n",
              " '72610',\n",
              " 'yuku',\n",
              " 'orleans',\n",
              " 'whip',\n",
              " 'gigante',\n",
              " 'edged',\n",
              " 'longhornmoma',\n",
              " 'norm',\n",
              " 'ewwygooey',\n",
              " 'one30',\n",
              " 'chins',\n",
              " 'home',\n",
              " 'twoflavor',\n",
              " '91',\n",
              " 'ofbut',\n",
              " 'decreased',\n",
              " 'cannedbut',\n",
              " 'jol',\n",
              " '130mg',\n",
              " 'vol',\n",
              " '365',\n",
              " 'abc',\n",
              " 'heavens',\n",
              " 'starbucks',\n",
              " '600',\n",
              " 'impossibletoresist',\n",
              " 'crockette',\n",
              " 'boats',\n",
              " 'kabobsyou',\n",
              " 'tysoncom',\n",
              " 'aesthetics',\n",
              " 'winers',\n",
              " 'arthurs',\n",
              " 'hatched',\n",
              " 'option',\n",
              " 'cleggs',\n",
              " 'dieting',\n",
              " 'oneofakind',\n",
              " 'manor',\n",
              " 'waitress',\n",
              " 'etcthis',\n",
              " 'httpwwwepicuriouscomrecipesfoodviews10520',\n",
              " 'ostracism',\n",
              " 'dares',\n",
              " 'lasagnamaking',\n",
              " 'incorrectly',\n",
              " 'wboiled',\n",
              " 'license',\n",
              " 'quickthis',\n",
              " 'transfering',\n",
              " 'fits',\n",
              " 'taylortwo',\n",
              " 'carrie',\n",
              " '2008',\n",
              " 'httpwwwfoodnetworkcomrecipesinagartenmoroccancouscousrecipeindexhtml',\n",
              " 'cornstarch',\n",
              " 'aimply',\n",
              " 'mistakes',\n",
              " 'liberty',\n",
              " 'halfbaked',\n",
              " 'manjarblanco',\n",
              " 'recipe89007',\n",
              " 'zwt6',\n",
              " '102933',\n",
              " 'graced',\n",
              " 'follow',\n",
              " 'faviorite',\n",
              " 'hummus',\n",
              " 'alongwith',\n",
              " 'fixes',\n",
              " 'guisada',\n",
              " 'bridge',\n",
              " 'chourio',\n",
              " 'lyrical',\n",
              " 'wwcooking',\n",
              " 'betterif',\n",
              " 'assets',\n",
              " 'smooth',\n",
              " 'mustardif',\n",
              " 'fact',\n",
              " 'disney',\n",
              " 'lenas',\n",
              " 'bouillon',\n",
              " 'addaption',\n",
              " 'hte',\n",
              " 'quick',\n",
              " 'marinadecautionthis',\n",
              " 'provides',\n",
              " 'africanote',\n",
              " 'boast',\n",
              " 'nasi',\n",
              " 'fatcaloriescholesterol',\n",
              " 'plays',\n",
              " 'travels',\n",
              " 'sisterteam',\n",
              " 'oelek',\n",
              " 'veal',\n",
              " 'lucile',\n",
              " 'mostest',\n",
              " '184762',\n",
              " 'housetoasted',\n",
              " 'expectations',\n",
              " 'tease',\n",
              " 'tucker',\n",
              " 'arduous',\n",
              " 'trickiest',\n",
              " 'pieyou',\n",
              " 'drinky',\n",
              " 'moistdo',\n",
              " 'entice',\n",
              " 'kugels',\n",
              " 'preferenceprep',\n",
              " 'twothirds',\n",
              " 'driveins',\n",
              " 'icingthe',\n",
              " 'leaness',\n",
              " 'spread',\n",
              " 'fresh',\n",
              " 'wed',\n",
              " 'goodprep',\n",
              " 'elysian',\n",
              " 'cindy',\n",
              " 'respond',\n",
              " 'timesapril',\n",
              " 'riper',\n",
              " 'hectic',\n",
              " 'refrig',\n",
              " 'wooden',\n",
              " 'likesdislikes',\n",
              " 'spring',\n",
              " 'congocookbookcom',\n",
              " 'tollhouse',\n",
              " 'curls',\n",
              " 'tulip',\n",
              " 'zealand',\n",
              " 'sunomono',\n",
              " 'trends',\n",
              " 'lessen',\n",
              " 'consistency',\n",
              " 'highend',\n",
              " 'plane',\n",
              " '8inch',\n",
              " 'coarsely',\n",
              " 'expeditions',\n",
              " 'flavorand',\n",
              " 'cookingi',\n",
              " 'grapes',\n",
              " 'coatingspread',\n",
              " 'traders',\n",
              " 'mayonaise',\n",
              " 'delictable',\n",
              " 'surreal',\n",
              " 'lennies',\n",
              " '17th',\n",
              " 'jennifer',\n",
              " 'dohope',\n",
              " 'bouillie',\n",
              " 'cilantro',\n",
              " 'goldstein',\n",
              " 'kimballs',\n",
              " 'chitterling',\n",
              " 'guild',\n",
              " 'cakei',\n",
              " 'cheesethis',\n",
              " 'cursive',\n",
              " 'solomon',\n",
              " 'sent',\n",
              " 'expansion',\n",
              " 'moderately',\n",
              " 'tastesso',\n",
              " 'sprung',\n",
              " 'color',\n",
              " 'rampantscotlandcom',\n",
              " 'moberly',\n",
              " 'deliciousto',\n",
              " 'foley',\n",
              " 'kiddies',\n",
              " 'motivessubterfuge',\n",
              " 'complained',\n",
              " 'gartenbarefoot',\n",
              " 'ascorbic',\n",
              " 'wrights',\n",
              " 'jarred',\n",
              " 'homebaked',\n",
              " 'percent',\n",
              " 'oberon',\n",
              " 'myo',\n",
              " 'caloriesmodified',\n",
              " '39lb',\n",
              " 'postbaking',\n",
              " 'healthyand',\n",
              " 'puffsa',\n",
              " 'venture',\n",
              " 'dignitaries',\n",
              " '95600',\n",
              " 'subru',\n",
              " 'tooif',\n",
              " 'wonderfulupdate',\n",
              " 'acted',\n",
              " 'reccomended',\n",
              " 'livre',\n",
              " 'countries',\n",
              " 'tablesoon',\n",
              " 'steamedbuttered',\n",
              " 'serviings',\n",
              " 'fizzy',\n",
              " 'goer',\n",
              " 'hanger',\n",
              " 'chillis',\n",
              " '7oz',\n",
              " 'naysayers',\n",
              " 'nightssource',\n",
              " 'yaki',\n",
              " 'skeleton',\n",
              " 'mccalls',\n",
              " 'school',\n",
              " 'f',\n",
              " 'slowbut',\n",
              " 'flags',\n",
              " 'arne',\n",
              " 'forman',\n",
              " 'lourdes',\n",
              " 'increadibly',\n",
              " 'r',\n",
              " 'hots',\n",
              " 'enjoymenti',\n",
              " 'batterwe',\n",
              " 'doeser',\n",
              " 'abdul',\n",
              " '86768',\n",
              " 'vanillia',\n",
              " 'iisooooo',\n",
              " 'limes',\n",
              " 'tubeshaped',\n",
              " 'saskatoon',\n",
              " 'breadbowl',\n",
              " 'quakeroatmealcomif',\n",
              " 'mmmmms',\n",
              " 'springsummertime',\n",
              " 'restauraunt',\n",
              " 'arrival',\n",
              " '509',\n",
              " 'thisive',\n",
              " 'flyleaf',\n",
              " 'frappecrisco',\n",
              " 'mommom',\n",
              " 'makeup',\n",
              " 'crust',\n",
              " 'bangers',\n",
              " 'baconthe',\n",
              " 'potatoesadapted',\n",
              " 'precooking',\n",
              " '5tbsp',\n",
              " 'smacking',\n",
              " 'sincethey',\n",
              " 'pics',\n",
              " 'samp',\n",
              " 'guts',\n",
              " 'aboard',\n",
              " 'tomatoesand',\n",
              " 'increased',\n",
              " 'panful',\n",
              " 'saladfrom',\n",
              " 'baboons',\n",
              " 'forums',\n",
              " 'zum',\n",
              " 'lacks',\n",
              " 'decendants',\n",
              " 'orzo',\n",
              " 'societies',\n",
              " 'liberia',\n",
              " 'growers',\n",
              " 'forced',\n",
              " 'pinconning',\n",
              " 'butterflied',\n",
              " 'umph',\n",
              " 'httpwwwrecipezaarcomzaatar65710',\n",
              " 'corsican',\n",
              " 'recipesourcecom',\n",
              " 'sperry',\n",
              " 'piecesfrom',\n",
              " 'hertzberg',\n",
              " 'extraordinary',\n",
              " 'adelaide',\n",
              " '2005marnating',\n",
              " 'thinskinned',\n",
              " '86105',\n",
              " 'hundreds',\n",
              " 'variants',\n",
              " 'salsatype',\n",
              " 'yumyumyum',\n",
              " '375',\n",
              " 'propane',\n",
              " 'lychees',\n",
              " 'beforehandthat',\n",
              " 'icons',\n",
              " 'diversion',\n",
              " 'argentinean',\n",
              " 'notice',\n",
              " 'asy',\n",
              " 'parmegiano',\n",
              " 'spaetzle',\n",
              " 'penniesone',\n",
              " 'tough',\n",
              " 'disclose',\n",
              " 'heading',\n",
              " 'decoration',\n",
              " 'askes',\n",
              " 'cadbury',\n",
              " 'nonexistent',\n",
              " 'seas',\n",
              " 'appetizerhttpwwwbettycrockercomrecipesrecipeaspxrecipeid35935sourcesearchresultpagetermscheese20appetizers',\n",
              " 'smidgen',\n",
              " 'crediting',\n",
              " 'antidiet',\n",
              " 'tupperware',\n",
              " 'released',\n",
              " 'symbolize',\n",
              " 'consumed',\n",
              " 'derived',\n",
              " 'ohsosimple',\n",
              " 'quickbake',\n",
              " '134834',\n",
              " 'scatter',\n",
              " 'moistive',\n",
              " 'daas',\n",
              " 'grillcooking',\n",
              " 'bubelach',\n",
              " 'arugula',\n",
              " 'thesenote',\n",
              " 'gallery',\n",
              " 'reez',\n",
              " 'wrapive',\n",
              " 'hike',\n",
              " 'instruction',\n",
              " 'chicke',\n",
              " 'toothpick',\n",
              " 'preferance',\n",
              " 'preventioncom',\n",
              " 'drips',\n",
              " 'tuesday',\n",
              " 'snacky',\n",
              " 'ornish',\n",
              " 'marler',\n",
              " 'enjoyi',\n",
              " 'accepted',\n",
              " 'strip',\n",
              " 'herebut',\n",
              " 'storescooking',\n",
              " 'phytonutrient',\n",
              " 'spoiling',\n",
              " 'cookiesit',\n",
              " 'rollison',\n",
              " 'bibim',\n",
              " 'harvests',\n",
              " 'mimi',\n",
              " 'wimpy',\n",
              " 'kievs',\n",
              " 'invert',\n",
              " 'combinationnot',\n",
              " 'taiwanese',\n",
              " 'zarians',\n",
              " 'bisquits',\n",
              " '11yo',\n",
              " 'pud',\n",
              " 'accompanyment',\n",
              " 'lagers',\n",
              " 'illini',\n",
              " 'abundantly',\n",
              " 'timecook',\n",
              " 'allrecipe',\n",
              " 'artist',\n",
              " 'fibrous',\n",
              " 'looking',\n",
              " 'honour',\n",
              " 'sproutsalways',\n",
              " 'doneness',\n",
              " 'gutbuster',\n",
              " 'aims',\n",
              " 'slant',\n",
              " 'togethers',\n",
              " 'ranted',\n",
              " 'switching',\n",
              " 'prot',\n",
              " 'frachelimecayenne',\n",
              " 'recipegreen',\n",
              " 'ratios',\n",
              " 'ginseng',\n",
              " 'bierocks',\n",
              " 'pakoras',\n",
              " 'isbut',\n",
              " 'timeplan',\n",
              " 'clean',\n",
              " 'toooooo',\n",
              " 'wellingtons',\n",
              " 'cube',\n",
              " 'bolillos',\n",
              " 'heinz',\n",
              " 'bohemian',\n",
              " 'bewaremake',\n",
              " 'neta',\n",
              " 'leaden',\n",
              " '124',\n",
              " 'africas',\n",
              " 'filler',\n",
              " '48587',\n",
              " 'dollars',\n",
              " 'congealed',\n",
              " 'cooing',\n",
              " 'saturates08',\n",
              " 'creamtwo',\n",
              " 'itits',\n",
              " 'brickletype',\n",
              " 'turorial',\n",
              " 'potatoe',\n",
              " 'brenda',\n",
              " 'humbles',\n",
              " 'favorit',\n",
              " 'doodlefathr',\n",
              " 'smashed',\n",
              " 'eons',\n",
              " 'nuefchatel',\n",
              " 'creamandbaconloving',\n",
              " 'elmotoo',\n",
              " 'yearsno',\n",
              " 'hydration',\n",
              " 'fezs',\n",
              " 'foodsure',\n",
              " 'herby',\n",
              " 'recipesand',\n",
              " 'juenessas',\n",
              " 'soothing',\n",
              " 'accounts',\n",
              " 'translation',\n",
              " 'ticked',\n",
              " '163426',\n",
              " 'mcdermott',\n",
              " 'reputable',\n",
              " 'dripping',\n",
              " 'deciphering',\n",
              " 'trappers',\n",
              " 'bremerton',\n",
              " 'croutons',\n",
              " 'whipice',\n",
              " 'oily',\n",
              " 'casas',\n",
              " 'thisalthough',\n",
              " 'mimosa',\n",
              " 'kadami',\n",
              " 'buggers',\n",
              " 'gambia',\n",
              " 'inbox',\n",
              " 'youi',\n",
              " 'aust',\n",
              " 'ok',\n",
              " 'glut',\n",
              " 'dampen',\n",
              " '12lbs',\n",
              " 'tbones',\n",
              " 'tamale',\n",
              " 'mtoozee',\n",
              " 'longing',\n",
              " 'piercing',\n",
              " 'zukes',\n",
              " 'swift',\n",
              " '89204',\n",
              " '9x5',\n",
              " 'brian',\n",
              " 'sheba',\n",
              " 'noncreamy',\n",
              " 'gfiber',\n",
              " 'bisque',\n",
              " 'complaining',\n",
              " 'topnotch',\n",
              " 'decadant',\n",
              " 'barbie',\n",
              " 'wool',\n",
              " 'outta',\n",
              " 'filmed',\n",
              " 'carney',\n",
              " 'carotene',\n",
              " 'simpleif',\n",
              " 'individualsize',\n",
              " '427',\n",
              " '218703',\n",
              " 'rockies',\n",
              " 'shabbos',\n",
              " 'pads',\n",
              " 'index',\n",
              " 'gentiles',\n",
              " 'stringy',\n",
              " 'farfelle',\n",
              " 'ceramic',\n",
              " 'fryer',\n",
              " 'bonfire',\n",
              " 'sopesanything',\n",
              " 'ichimi',\n",
              " 'ingredientslean',\n",
              " 'damned',\n",
              " 'sharwoods',\n",
              " 'minutes6',\n",
              " 'delish3',\n",
              " 'shelly',\n",
              " 'sanchez',\n",
              " 'hate',\n",
              " 'bergys',\n",
              " 'pound',\n",
              " '2010for',\n",
              " 'fiona',\n",
              " 'bowdoin',\n",
              " 'himself',\n",
              " 'compuserve',\n",
              " 'onepot',\n",
              " 'tell',\n",
              " 'candylike',\n",
              " 'astors',\n",
              " 'preheat',\n",
              " 'dishthis',\n",
              " 'twink',\n",
              " 'mostess',\n",
              " 'pressurized',\n",
              " 'bowness',\n",
              " 'bourbons',\n",
              " 'shishkebab',\n",
              " 'decongestion',\n",
              " 'revive',\n",
              " 'offering',\n",
              " 'rock',\n",
              " 'lilt',\n",
              " 'gland',\n",
              " 'sauting',\n",
              " 'substite',\n",
              " 'waaay',\n",
              " 'tastefull',\n",
              " 'fumet',\n",
              " 'crystal',\n",
              " 'combination',\n",
              " 'grow',\n",
              " 'amazon',\n",
              " 'deserves',\n",
              " 'vfw',\n",
              " 'whitehead',\n",
              " 'pamphlet',\n",
              " 'cushing',\n",
              " 'crokers',\n",
              " 'brainstorm',\n",
              " 'pointsserving',\n",
              " 'hunkered',\n",
              " 'citizens',\n",
              " 'guarded',\n",
              " 'partythis',\n",
              " 'lawrys',\n",
              " 'trimperfect',\n",
              " 'ticket',\n",
              " 'romantic',\n",
              " 'magana',\n",
              " 'cork',\n",
              " 'informationupdate',\n",
              " 'mangoflavored',\n",
              " 'cafemomcom',\n",
              " 'slabs',\n",
              " 'minneapolis',\n",
              " 'arrabiata',\n",
              " 'studentchef',\n",
              " 'goodor',\n",
              " '18th',\n",
              " 'thoroughly',\n",
              " 'laborous',\n",
              " 'sixth',\n",
              " 'recipe406664',\n",
              " 'twocrust',\n",
              " 'welsh',\n",
              " 'annas',\n",
              " 'orig',\n",
              " 'industry',\n",
              " 'lookinggreat',\n",
              " 'swore',\n",
              " 'superstitious',\n",
              " 'steer',\n",
              " 'citrus',\n",
              " 'artisan',\n",
              " 'summers',\n",
              " 'borders',\n",
              " 'grosses',\n",
              " 'stockings',\n",
              " 'satiety',\n",
              " 'scan',\n",
              " 'stroganoffstyle',\n",
              " 'upset',\n",
              " 'dashguesstimate',\n",
              " 'definetely',\n",
              " 'competitions',\n",
              " 'thaiders',\n",
              " 'devotee',\n",
              " 'panfry',\n",
              " 'previously',\n",
              " 'readymade',\n",
              " 'mex',\n",
              " 'dippingnote',\n",
              " 'louisianahere',\n",
              " 'viennese',\n",
              " 'followed',\n",
              " 'install',\n",
              " 'amy',\n",
              " 'adventurous',\n",
              " 'baja',\n",
              " 'floridanative',\n",
              " 'olivida',\n",
              " 'procedural',\n",
              " 'tomatoesprep',\n",
              " 'narrow',\n",
              " 'ziti',\n",
              " '33',\n",
              " 'hoiday',\n",
              " 'saythis',\n",
              " 'jefes',\n",
              " 'lellis',\n",
              " 'bakesheet',\n",
              " 'toritos',\n",
              " 'thinnerskinned',\n",
              " 'stgermains',\n",
              " 'greenred',\n",
              " 'haunted',\n",
              " 'covers',\n",
              " 'reserved',\n",
              " 'killer',\n",
              " 'fruitysweet',\n",
              " 'only',\n",
              " 'energetic',\n",
              " 'hinnies',\n",
              " 'protip',\n",
              " 'suprisingly',\n",
              " 'iced',\n",
              " 'heattime',\n",
              " 'picada',\n",
              " 'httpwwwbbcgoodfoodcomrecipes9099lancashirehotpot',\n",
              " 'saladin',\n",
              " '60314',\n",
              " 'dayafter',\n",
              " 'vet',\n",
              " 'peasi',\n",
              " 'zaarit',\n",
              " 'cheapskate',\n",
              " 'hmmi',\n",
              " 'soupsongcom',\n",
              " 'toghther',\n",
              " 'european',\n",
              " 'charro',\n",
              " 'katona',\n",
              " 'nonpumpkin',\n",
              " 'misprint',\n",
              " '166973',\n",
              " 'rainy',\n",
              " 'fullest',\n",
              " 'enjoyof',\n",
              " 'grandaughter',\n",
              " 'scarlet',\n",
              " 'coveted',\n",
              " 'sindhi',\n",
              " 'games',\n",
              " 'jorges',\n",
              " 'whiffletree',\n",
              " 'bet',\n",
              " 'floridai',\n",
              " 'phenols',\n",
              " 'dayold',\n",
              " 'road',\n",
              " 'ae',\n",
              " 'tonighti',\n",
              " 'made',\n",
              " 'waaaay',\n",
              " 'canada',\n",
              " 'polychlorinated',\n",
              " 'concision',\n",
              " 'bands',\n",
              " 'cooks',\n",
              " 'hergrandmother',\n",
              " 'contribution',\n",
              " 'portland',\n",
              " 'seperately',\n",
              " 'rick',\n",
              " 'trips',\n",
              " 'user',\n",
              " 'grigsons',\n",
              " 'wheatfreeglutenfree',\n",
              " 'eversolight',\n",
              " 'macnabs',\n",
              " 'nights',\n",
              " 'oct11',\n",
              " 'semidried',\n",
              " 'squeze',\n",
              " 'spritzer',\n",
              " 'potgo',\n",
              " 'anjum',\n",
              " 'discoloration',\n",
              " 'replace',\n",
              " 'silverdollarsize',\n",
              " 'secords',\n",
              " 'tomatomozzarella',\n",
              " 'fluffy',\n",
              " 'hush',\n",
              " 'magazineits',\n",
              " '185162',\n",
              " 'safari',\n",
              " 'eastas',\n",
              " 'familyfuncom',\n",
              " 'deni',\n",
              " 'engine',\n",
              " 'wonderfulthis',\n",
              " 'completeprotein',\n",
              " 'itfor',\n",
              " 'swigs',\n",
              " 'seasoningi',\n",
              " 'pineappledelicious',\n",
              " 'fatfree',\n",
              " 'recipesi',\n",
              " 'kraut',\n",
              " 'breat',\n",
              " 'incude',\n",
              " 'twostage',\n",
              " 'ricedelicious',\n",
              " 'chhicken',\n",
              " 'pannans',\n",
              " 'meaning',\n",
              " 'boyfriend',\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Vd0d8CJJfq7"
      },
      "source": [
        "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.metrics.distance import edit_distance\n",
        "for i in range(5):\n",
        "  a = random.choices(list(words), k=2)\n",
        "  print(a)\n",
        "  print(edit_distance(a[0], a[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAmh2_L6zLUH",
        "outputId": "18f757e5-c02f-4d3a-d0d9-ea01ec325cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fling', 'apply']\n",
            "5\n",
            "['dieniab', 'matteri']\n",
            "7\n",
            "['rellena', 'names']\n",
            "6\n",
            "['hamburgers', 'heavens']\n",
            "7\n",
            "['purpose', 'aaas']\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ1kldcAJfq7"
      },
      "source": [
        "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f1(word, k):\n",
        "  min_w = {}\n",
        "  for i in words:\n",
        "    min_w[i] = edit_distance(i, word)\n",
        "  msort = sorted(min_w.items(), key=lambda x: x[1])\n",
        "  for i in dict(msort[:k]).keys():\n",
        "    print(i)\n",
        "\n",
        "f1('sdfr', 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzbo2CrU1ojr",
        "outputId": "2da786ff-8e83-400f-8a2a-278bd66b0b1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sur\n",
            "skyr\n",
            "sf\n",
            "dfw\n",
            "sear\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kr6p00BJfq7"
      },
      "source": [
        "### Стемминг, лемматизация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR6LNoTTJfq7"
      },
      "source": [
        "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
        "    * word\n",
        "    * stemmed_word \n",
        "    * normalized_word \n",
        "\n",
        "Столбец `word` укажите в качестве индекса. \n",
        "\n",
        "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "snb_stemmer_eng = SnowballStemmer('english')\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "2Cuuoz9473Kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"rocks\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "OoWsQyut-LPs",
        "outputId": "32e06c9b-d793-4f61-a54f-60e2c4656c13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rock'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s1, s2 = [], []\n",
        "for i in words:\n",
        "  s1.append(snb_stemmer_eng.stem(i))\n",
        "  s2.append(lemmatizer.lemmatize(i))\n",
        "words1 = pd.DataFrame({'stemmed_word': s1,\n",
        "                       'normalized_word': s2})\n",
        "words1.index = words\n",
        "words1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "BzPbubly7g5p",
        "outputId": "99edfd13-e8d5-448a-c0f7-926b88878364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          stemmed_word normalized_word\n",
              "mesclun        mesclun         mesclun\n",
              "lynched          lynch         lynched\n",
              "00mg              00mg            00mg\n",
              "snapper        snapper         snapper\n",
              "daykind        daykind         daykind\n",
              "...                ...             ...\n",
              "omission         omiss        omission\n",
              "noncooker      noncook       noncooker\n",
              "liked             like           liked\n",
              "dhal              dhal            dhal\n",
              "mingles          mingl         mingles\n",
              "\n",
              "[32868 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32eb0cf3-2d66-44ed-9e4e-0db266981f73\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stemmed_word</th>\n",
              "      <th>normalized_word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mesclun</th>\n",
              "      <td>mesclun</td>\n",
              "      <td>mesclun</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lynched</th>\n",
              "      <td>lynch</td>\n",
              "      <td>lynched</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00mg</th>\n",
              "      <td>00mg</td>\n",
              "      <td>00mg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>snapper</th>\n",
              "      <td>snapper</td>\n",
              "      <td>snapper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>daykind</th>\n",
              "      <td>daykind</td>\n",
              "      <td>daykind</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>omission</th>\n",
              "      <td>omiss</td>\n",
              "      <td>omission</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>noncooker</th>\n",
              "      <td>noncook</td>\n",
              "      <td>noncooker</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>liked</th>\n",
              "      <td>like</td>\n",
              "      <td>liked</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dhal</th>\n",
              "      <td>dhal</td>\n",
              "      <td>dhal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mingles</th>\n",
              "      <td>mingl</td>\n",
              "      <td>mingles</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32868 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32eb0cf3-2d66-44ed-9e4e-0db266981f73')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32eb0cf3-2d66-44ed-9e4e-0db266981f73 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32eb0cf3-2d66-44ed-9e4e-0db266981f73');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1CPoVdAJfq7"
      },
      "source": [
        "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "P8EJdKx4CUFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dw = {}\n",
        "for i in recipes.preprocessed_descriptions:\n",
        "  for j in nltk.word_tokenize(str(i)):\n",
        "    if j in dw.keys():\n",
        "      dw[j] += 1\n",
        "    else:\n",
        "      dw[j] = 1\n",
        "dw_sort = sorted(dw.items(), key=lambda x: x[1])\n",
        "dw_sort[-10:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYjL_BE5FCOg",
        "outputId": "18bb8e63-e3d3-4e5b-ff3b-d3fd26cc430f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('for', 15939),\n",
              " ('of', 18364),\n",
              " ('it', 19756),\n",
              " ('is', 20285),\n",
              " ('to', 23471),\n",
              " ('i', 24836),\n",
              " ('this', 26859),\n",
              " ('and', 30245),\n",
              " ('a', 34951),\n",
              " ('the', 40072)]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords_eng = stopwords.words('english')\n",
        "words_len = 0\n",
        "words_st = 0\n",
        "rez = []\n",
        "for i in recipes.preprocessed_descriptions:\n",
        "  for j in nltk.word_tokenize(str(i)): \n",
        "    words_len += 1\n",
        "    if j not in stopwords_eng:\n",
        "      rez.append(j)\n",
        "    else:\n",
        "      words_st += 1\n",
        "      \n",
        "words_st/words_len*100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVhVILbGCWLc",
        "outputId": "99d7ce15-5292-4562-a0de-d8f2f00f9904"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45.64649471672189"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dw = {}\n",
        "for j in rez:\n",
        "  if j in dw.keys():\n",
        "    dw[j] += 1\n",
        "  else:\n",
        "    dw[j] = 1\n",
        "dw_sort = sorted(dw.items(), key=lambda x: x[1])\n",
        "dw_sort[-10:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJSJKVp5D-4r",
        "outputId": "31339344-3a70-4c60-83aa-91e1256f8765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('good', 3791),\n",
              " ('made', 3810),\n",
              " ('one', 3872),\n",
              " ('easy', 4152),\n",
              " ('like', 4167),\n",
              " ('great', 4430),\n",
              " ('use', 4620),\n",
              " ('time', 5137),\n",
              " ('make', 6326),\n",
              " ('recipe', 14871)]"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvyy1hQYJfq8"
      },
      "source": [
        "### Векторное представление текста"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_fBeVw_Jfq8"
      },
      "source": [
        "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import (CountVectorizer, TfidfVectorizer)\n",
        "tv = TfidfVectorizer()\n",
        "sp1=[]\n",
        "name = []\n",
        "k = random.choices([i for i in range(len(recipes))], k=5)\n",
        "for i in k:\n",
        "  sp1.append(recipes.preprocessed_descriptions[i])\n",
        "  name.append(recipes.name[i])\n",
        "corpus_tv = tv.fit_transform(list(sp1))\n",
        "corpus_tv.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvSnOtL8iN8u",
        "outputId": "ea048ae6-7566-4247-b192-756fef798a19"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.2694591 ,\n",
              "        0.        , 0.        , 0.        , 0.3339876 , 0.        ,\n",
              "        0.22367539, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.3339876 , 0.        ,\n",
              "        0.2694591 , 0.        , 0.        , 0.        , 0.3339876 ,\n",
              "        0.3339876 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.3339876 , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.22367539, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.3339876 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.18816279, 0.        , 0.22367539,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.07683945, 0.07683945, 0.07683945, 0.        , 0.        ,\n",
              "        0.07683945, 0.07683945, 0.23051835, 0.        , 0.        ,\n",
              "        0.05146028, 0.        , 0.07683945, 0.06199359, 0.        ,\n",
              "        0.07683945, 0.07683945, 0.07683945, 0.07683945, 0.        ,\n",
              "        0.07683945, 0.07683945, 0.07683945, 0.        , 0.07683945,\n",
              "        0.18598076, 0.07683945, 0.07683945, 0.07683945, 0.        ,\n",
              "        0.        , 0.07683945, 0.07683945, 0.07683945, 0.06199359,\n",
              "        0.        , 0.        , 0.        , 0.23051835, 0.        ,\n",
              "        0.07683945, 0.07683945, 0.        , 0.12398717, 0.07683945,\n",
              "        0.07683945, 0.07683945, 0.        , 0.1536789 , 0.07683945,\n",
              "        0.30735781, 0.1536789 , 0.        , 0.        , 0.07683945,\n",
              "        0.07683945, 0.        , 0.        , 0.        , 0.07683945,\n",
              "        0.        , 0.07683945, 0.07683945, 0.        , 0.07683945,\n",
              "        0.07683945, 0.        , 0.07683945, 0.07683945, 0.07683945,\n",
              "        0.25730138, 0.07683945, 0.10292055, 0.        , 0.        ,\n",
              "        0.07683945, 0.07683945, 0.        , 0.        , 0.07683945,\n",
              "        0.        , 0.        , 0.1536789 , 0.1536789 , 0.        ,\n",
              "        0.07683945, 0.07683945, 0.07683945, 0.07683945, 0.07683945,\n",
              "        0.07683945, 0.        , 0.        , 0.07683945, 0.07683945,\n",
              "        0.        , 0.        , 0.        , 0.07683945, 0.07683945,\n",
              "        0.07683945, 0.07683945, 0.07683945, 0.07683945, 0.07683945,\n",
              "        0.24797434, 0.07683945, 0.17316003, 0.07683945, 0.05146028,\n",
              "        0.12398717, 0.        , 0.        , 0.07683945, 0.07683945,\n",
              "        0.07683945, 0.07683945, 0.07683945, 0.07683945, 0.07683945,\n",
              "        0.07683945, 0.12398717, 0.07683945, 0.23051835],\n",
              "       [0.        , 0.        , 0.        , 0.24585242, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.19835218, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.24585242,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.24585242, 0.        , 0.24585242,\n",
              "        0.        , 0.        , 0.        , 0.19835218, 0.        ,\n",
              "        0.        , 0.        , 0.24585242, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.24585242, 0.24585242, 0.        ,\n",
              "        0.        , 0.        , 0.24585242, 0.        , 0.        ,\n",
              "        0.24585242, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.16465023, 0.24585242, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.24585242, 0.        ,\n",
              "        0.24585242, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.24585242, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.32930046,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.18549422,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.22991531,\n",
              "        0.15397696, 0.22991531, 0.        , 0.        , 0.22991531,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.18549422,\n",
              "        0.        , 0.22991531, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.22991531, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.22991531, 0.        ,\n",
              "        0.        , 0.22991531, 0.        , 0.        , 0.        ,\n",
              "        0.15397696, 0.        , 0.15397696, 0.        , 0.22991531,\n",
              "        0.        , 0.        , 0.22991531, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.22991531,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.22991531, 0.        , 0.        ,\n",
              "        0.22991531, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.18549422, 0.        , 0.12953027, 0.        , 0.        ,\n",
              "        0.18549422, 0.22991531, 0.22991531, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.18549422, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.48127008, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.48127008, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.48127008, 0.48127008, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.27113917, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import (CountVectorizer, TfidfVectorizer)\n",
        "corpus = ['from the pacific northwest region the region is known for great apples  posted for zaar world tour iii',\n",
        " 'this is a variation of bean soup that i developed when i was out of an ingredient  now its the only way i will make bean soup',\n",
        " 'this is another nice summer drink good with alcohol also good without all my drinks can be made with or without alcoholits always your choice',\n",
        " 'this is a combination of a couple of recipes i found and adapted into one hope you like it',\n",
        " 'im told this is the guacamole from chipotles im also told that haas avocados are the key but i really have no idea if thats a set in stone fact ive never had chipotles guacamole as there are none near me but i have had this and i sure do like it no matter who came up with it']\n",
        "tv = TfidfVectorizer()\n",
        "corpus_tv = tv.fit_transform(corpus)\n",
        "corpus_tv.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRUFu0WYk4zZ",
        "outputId": "b860b13c-d0e6-4a10-a836-b0d4eeeb29b6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.21994214,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.43988429, 0.        , 0.17744794,\n",
              "        0.        , 0.21994214, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.21994214,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.10480361,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.21994214,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.21994214, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.21994214, 0.21994214,\n",
              "        0.        , 0.        , 0.43988429, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.29459563, 0.        , 0.        , 0.        , 0.21994214,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.21994214,\n",
              "        0.        , 0.        , 0.21994214],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.19901709, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.39803418,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.19901709, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.19901709, 0.        , 0.09483271,\n",
              "        0.        , 0.19901709, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.19901709, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.19901709, 0.32113147, 0.        ,\n",
              "        0.19901709, 0.        , 0.19901709, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.39803418,\n",
              "        0.        , 0.        , 0.        , 0.16056573, 0.        ,\n",
              "        0.13328406, 0.        , 0.11212276, 0.        , 0.        ,\n",
              "        0.        , 0.19901709, 0.19901709, 0.19901709, 0.19901709,\n",
              "        0.        , 0.19901709, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.18966409, 0.18966409, 0.18966409, 0.1530198 ,\n",
              "        0.18966409, 0.        , 0.        , 0.18966409, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.18966409, 0.        ,\n",
              "        0.        , 0.        , 0.18966409, 0.        , 0.18966409,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.18966409,\n",
              "        0.18966409, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.37932819, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.09037596,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.18966409, 0.        , 0.        , 0.        ,\n",
              "        0.18966409, 0.        , 0.        , 0.18966409, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.18966409, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.18966409, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.10685344, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.30603959, 0.37932819, 0.        ,\n",
              "        0.        , 0.18966409, 0.        ],\n",
              "       [0.26630361, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.21485207, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.26630361, 0.26630361, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.26630361, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.26630361, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.26630361, 0.1268951 ,\n",
              "        0.21485207, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.21485207, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.42970415, 0.26630361,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.26630361, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.15003081, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.26630361, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.09656843,\n",
              "        0.        , 0.        , 0.09656843, 0.        , 0.        ,\n",
              "        0.23938817, 0.11969408, 0.11969408, 0.        , 0.        ,\n",
              "        0.23938817, 0.11969408, 0.        , 0.23938817, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.11969408, 0.        ,\n",
              "        0.        , 0.11969408, 0.        , 0.        , 0.09656843,\n",
              "        0.        , 0.        , 0.23938817, 0.11969408, 0.23938817,\n",
              "        0.23938817, 0.        , 0.11969408, 0.11969408, 0.        ,\n",
              "        0.23938817, 0.11969408, 0.        , 0.        , 0.05703487,\n",
              "        0.19313687, 0.        , 0.11969408, 0.11969408, 0.        ,\n",
              "        0.09656843, 0.        , 0.        , 0.11969408, 0.11969408,\n",
              "        0.        , 0.11969408, 0.11969408, 0.        , 0.23938817,\n",
              "        0.11969408, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.11969408, 0.        , 0.        , 0.11969408, 0.        ,\n",
              "        0.11969408, 0.        , 0.11969408, 0.09656843, 0.11969408,\n",
              "        0.16032105, 0.11969408, 0.13486712, 0.23938817, 0.        ,\n",
              "        0.11969408, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.11969408, 0.        , 0.09656843, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ3CES9tJfq8"
      },
      "source": [
        "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import distance\n",
        "s = {}\n",
        "vectors = corpus_tv.toarray()\n",
        "for i1 in range(len(vectors)):\n",
        "    for i2 in range(i1 + 1, len(vectors)):\n",
        "        print(i1, i2, \":\", distance.cosine(vectors[i1], vectors[i2]))\n",
        "        s[name[i1]] = [i1, i2, distance.cosine(vectors[i1], vectors[i2])]\n",
        "pd.DataFrame(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "9uj3egaA2hO1",
        "outputId": "a2f425f0-be63-43ae-8399-f6c0ca9d361d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1 : 0.8367307382122389\n",
            "0 2 : 0.9263435917853129\n",
            "0 3 : 0.8567624045232969\n",
            "0 4 : 0.9489816978709935\n",
            "1 2 : 0.9292185263207237\n",
            "1 3 : 0.8106858929930132\n",
            "1 4 : 0.9530495346453971\n",
            "2 3 : 0.9746476584577148\n",
            "2 4 : 1.0\n",
            "3 4 : 0.9648792697924643\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sausage   cheese stuffed shells with tomato mushroom sauce  \\\n",
              "0                                           0.000000            \n",
              "1                                           4.000000            \n",
              "2                                           0.948982            \n",
              "\n",
              "   lentil dhal with roasted garlic  big island paniolo tri tip steak  \\\n",
              "0                          1.00000                               2.0   \n",
              "1                          4.00000                               4.0   \n",
              "2                          0.95305                               1.0   \n",
              "\n",
              "   blueberry maple syrup french toast  \n",
              "0                            3.000000  \n",
              "1                            4.000000  \n",
              "2                            0.964879  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-42ca9f77-b281-4f1b-9f2d-d9100a037cd5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sausage   cheese stuffed shells with tomato mushroom sauce</th>\n",
              "      <th>lentil dhal with roasted garlic</th>\n",
              "      <th>big island paniolo tri tip steak</th>\n",
              "      <th>blueberry maple syrup french toast</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.948982</td>\n",
              "      <td>0.95305</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.964879</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42ca9f77-b281-4f1b-9f2d-d9100a037cd5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-42ca9f77-b281-4f1b-9f2d-d9100a037cd5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-42ca9f77-b281-4f1b-9f2d-d9100a037cd5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2OajjzvJfq8"
      },
      "source": [
        "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат (словами)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7fgFsSdJfq8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}